#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os, json, tarfile, argparse, random, math
from collections import defaultdict, Counter
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm

# ---------------- Allowed labels ----------------
CLIN_SECONDARIES = [
    'x-ray radiography', 'optical coherence tomography', 'endoscopy', 
    'intraoral imaging', 'angiography', 'procedural image', 'skull', 'patient photo', 
    'functional magnetic resonance', 'magnetic resonance', 'eye', 'mammography', 
    'electrocardiography', 'clinical imaging', 'skin lesion', 'ultrasound', 
    'specimen', 'computerized tomography', 'laryngoscopy', 'teeth', 
    'intraoperative image', 'surgical procedure', 'brain'
]


# å¦å¤–å…è®¸çš„ Microscopyï¼š
MICRO_ALLOWED_SECONDARY = {'light microscopy'}

# éœ€è¦â€œå‡è¡¡â€çš„ç±»åˆ«ä»…ä¸ºä¸Šé¢çš„ 24 ä¸ª Clinical Imaging çš„äºŒçº§æ ‡ç­¾ï¼š
# BALANCE_CATEGORIES = CLIN_SECONDARIES[:]  # å¦‚è¦æŠŠ 'light microscopy' å½“ç¬¬25ç±»ï¼Œåªéœ€ append å³å¯

BALANCE_CATEGORIES = CLIN_SECONDARIES + ['light microscopy']

# K åˆ†å¸ƒ
K_DIST = {1: 0.90, 2: 0.02, 3: 0.02, 4: 0.02, 5: 0.02, 6: 0.02}
K_LIST = [1,2,3,4,5,6]

# ---------------- Utils ----------------
def normalize_caption(x):
    if x is None:
        return None
    s = str(x).strip()
    if not s or s.lower() == "no caption found":
        return None
    return s

def as_list_str(x):
    if x is None:
        return []
    if isinstance(x, list):
        return [("" if v is None else str(v)) for v in x]
    return [str(x)]

def to_lower_set(seq):
    return {s.strip().lower() for s in seq if isinstance(s, str)}

def collect_context_list(rec_context, image_id):
    """å…¼å®¹ dict{image_id:[...]} / list[{image_id:[...]}]ï¼Œè¿”å› list[str] å»é‡ä¿åº"""
    iid = str(image_id)
    out, seen = [], set()

    def _push(v):
        if v is None: v = ""
        v = str(v)
        if v not in seen:
            seen.add(v); out.append(v)

    if isinstance(rec_context, dict):
        for k, v in rec_context.items():
            if str(k) == iid:
                if isinstance(v, list):
                    for it in v: _push(it)
                else:
                    _push(v)
    elif isinstance(rec_context, list):
        for el in rec_context:
            if isinstance(el, dict):
                for k, v in el.items():
                    if str(k) == iid:
                        if isinstance(v, list):
                            for it in v: _push(it)
                        else:
                            _push(v)
    return out

def relpath_under(base_dir, abs_path):
    try:
        return os.path.relpath(abs_path, base_dir)
    except Exception:
        return abs_path

# ---------------- Worker: parse one tar ----------------
def process_tar(args):
    """
    è§£æä¸€ä¸ª tarï¼Œè¿”å› list[mini_rec]ã€‚
    mini_recï¼ˆæ¯å›¾ä¸€æ¡ï¼‰åŒ…å«ï¼š
      - image_id
      - article_accession_id, article_title
      - image_file_name, image_panel_type, image_panel_subtype
      - image_primary_label(list), image_secondary_label(list), image_size
      - captionï¼ˆè¯¥å›¾è‡ªå·±çš„ captionï¼‰
      - contextï¼ˆè¯¥å›¾è‡ªå·±çš„ context åˆ—è¡¨ï¼‰
      - image_wds_tarï¼ˆç›¸å¯¹ base çš„ tar è·¯å¾„ï¼‰
      - image_wds_memberï¼ˆjpg æˆå‘˜è·¯å¾„ï¼‰
      - image_wds_pathï¼ˆæ‹¼æ¥ "tar::member"ï¼‰
    """
    tar_fp, base_dir = args
    out = []

    rel_tar = relpath_under(base_dir, tar_fp)
    try:
        with tarfile.open(tar_fp, "r") as tar:
            json_members = [m for m in tar.getmembers() if m.name.endswith(".json")]
            json_members.sort(key=lambda m: m.name)

            for jm in json_members:
                try:
                    raw = tar.extractfile(jm).read().decode("utf-8", "ignore")
                    rec = json.loads(raw)
                except Exception:
                    continue

                iid = rec.get("image_cluster_id")
                if not iid:
                    continue

                # captionï¼ˆimage_set é‡Œæ‰¾æœ¬å›¾çš„ï¼‰
                cap = None
                for imeta in (rec.get("image_set") or []):
                    if imeta and imeta.get("image_id") == iid:
                        cap = normalize_caption(imeta.get("caption"))
                        break

                ctx = collect_context_list(rec.get("image_context", {}), iid)

                jpg_member = os.path.splitext(jm.name)[0] + ".jpg"
                wds_member = jpg_member
                wds_tar = rel_tar
                wds_path = f"{wds_tar}::{wds_member}"

                primary = as_list_str(rec.get("image_primary_label"))
                secondary = as_list_str(rec.get("image_secondary_label"))

                mini = {
                    "image_id": iid,
                    "article_accession_id": rec.get("article_accession_id") or rec.get("pmid") or "",
                    "article_title": rec.get("article_title") or "",
                    "image_file_name": rec.get("image_file_name"),
                    "image_panel_type": rec.get("image_panel_type"),
                    "image_panel_subtype": rec.get("image_panel_subtype"),
                    "image_primary_label": primary,
                    "image_secondary_label": secondary,
                    "image_size": rec.get("image_size") or [None, None],
                    "caption": cap,
                    "context": ctx,
                    "image_wds_tar": wds_tar,
                    "image_wds_member": wds_member,
                    "image_wds_path": wds_path,
                }
                out.append(mini)
    except (tarfile.ReadError, EOFError):
        return []
    return out

# ---------------- Build index (parallel) ----------------
def build_mini_index_parallel(base_dir, workers):
    # æ”¶é›† tar
    tars = []
    for sub in ["commercial", "noncommercial", "other"]:
        d = os.path.join(base_dir, sub)
        if os.path.isdir(d):
            for f in os.listdir(d):
                if f.endswith(".tar"):
                    tars.append(os.path.join(d, f))
    tars.sort()

    minis = []
    with ProcessPoolExecutor(max_workers=workers) as ex:
        futures = [ex.submit(process_tar, (t, base_dir)) for t in tars]
        for fut in tqdm(as_completed(futures), total=len(futures), desc="Indexing TARs (parallel)"):
            minis.extend(fut.result())

    # ä¸¤ä¸ªç´¢å¼•ï¼šimage_id -> miniï¼› article -> list[mini]
    by_image = {m["image_id"]: m for m in minis}
    by_article = defaultdict(list)
    for m in minis:
        art = m["article_accession_id"]
        by_article[art].append(m)
    return by_image, by_article

# ---------------- Label filter ----------------
def is_allowed_image(mini):
    prim = to_lower_set(mini.get("image_primary_label") or [])
    sec  = to_lower_set(mini.get("image_secondary_label") or [])
    # Clinical Imaging + 24 ä»»æ„å…¶ä¸€
    if "clinical imaging" in prim and (sec & set(CLIN_SECONDARIES)):
        return True
    # Microscopy + light microscopyï¼ˆå…è®¸ï¼Œä½†å®ƒä¸å‚ä¸ 24 ç±»å‡è¡¡ï¼‰
    if "microscopy" in prim and ("light microscopy" in sec):
        return True
    return False

def image_categories(mini):
    """è¿”å›è¯¥å›¾å±äºå“ªäº›â€œå‡è¡¡ç±»åˆ«â€ï¼ˆå³ 24 ä¸ª Clinical secondariesï¼Œå–äº¤é›†ï¼‰ã€‚"""
    sec = to_lower_set(mini.get("image_secondary_label") or [])
    return list((sec & set(BALANCE_CATEGORIES)))

# ---------------- Discover groups (full-use) ----------------
def discover_groups_by_category(by_article, by_image, K_max=6):
    """
    åœ¨æ¯ç¯‡æ–‡ç« å†…éƒ¨ï¼Œç”¨â€œcaption å®Œå…¨ç›¸åŒâ€çš„å›¾ç‰‡ä½œä¸ºä¸€ä¸ªç»„ï¼›åªä½¿ç”¨ is_allowed_image=True çš„å›¾ç‰‡ï¼›
    ç»„çš„ç±»åˆ« = ç»„å†…æ‰€æœ‰å›¾ç‰‡ secondary çš„å¹¶é›† âˆ© BALANCE_CATEGORIESã€‚
    è¿”å›:
      per_cat_groups[K][cat] = [ tuple(sorted_ids), ... ]
      å…¨å±€å¯ç”¨ç»Ÿè®¡ available_per_cat[K][cat] = æ•°é‡
    """
    per_cat_groups = {k: defaultdict(list) for k in K_LIST}
    # éå†æ–‡ç« 
    for art, items in by_article.items():
        # å…ˆç­›æ‰ä¸å…è®¸çš„å›¾ï¼›ä¸”å¿…é¡»æœ‰ caption
        allowed_items = [m for m in items if is_allowed_image(m) and m.get("caption")]
        if not allowed_items:
            continue

        # caption -> [image_id,...]
        cap2ids = defaultdict(list)
        for it in allowed_items:
            cap2ids[it["caption"]].append(it["image_id"])

        # å¯¹æ¯ä¸ª caption ç»„ï¼Œå½¢æˆ full-use ç»„ï¼ˆä¸æˆªæ–­ï¼‰
        for cap, ids in cap2ids.items():
            K = len(ids)
            if K < 1 or K > K_max:
                continue
            ids_sorted = tuple(sorted(ids))
            # ç»„çš„ç±»åˆ«ï¼šç»„å†…æ‰€æœ‰å›¾çš„ secondary ä¹‹å¹¶é›† âˆ© 24 ç±»
            cats = set()
            for iid in ids_sorted:
                cats.update(image_categories(by_image[iid]))
            if not cats:
                # è¿™ç»„è™½ç„¶å…è®¸ï¼ˆå¯èƒ½æ˜¯ microscopyï¼‰ï¼Œä½†ä¸å±äº 24 ä¸ªå‡è¡¡ç±»ï¼›è·³è¿‡
                continue
            for c in cats:
                per_cat_groups[K][c].append(ids_sorted)

    # åšä¸ªç»Ÿè®¡ç”¨
    available = {k: {c: len(vs) for c, vs in per_cat_groups[k].items()} for k in K_LIST}
    return per_cat_groups, available

# ---------------- Targets ----------------
def split_evenly_total(N, cats):
    """æŠŠ N å¹³å‡åˆ†åˆ° len(cats) ä¸ªç±»åˆ«ï¼›ä½™æ•°ç»™å‰é¢çš„è‹¥å¹²ä¸ªã€‚"""
    q, r = divmod(N, len(cats))
    per = {c: q for c in cats}
    for c in cats[:r]:
        per[c] += 1
    return per

def compute_targets_per_cat(Nc, dist):
    """ç»™å•ä¸ªç±»åˆ« Ncï¼Œç®—å…¶ K é…é¢ï¼ˆå››èˆäº”å…¥åæŠŠè¯¯å·®è¡¥åˆ° K=1ï¼‰ã€‚"""
    t = {k: int(round(Nc * p)) for k, p in dist.items()}
    delta = Nc - sum(t.values())
    if delta != 0:
        t[1] = max(0, t.get(1, 0) + delta)
    return t

# ---------------- Sampling ----------------
def sample_by_category(per_cat_groups, per_cat_N, seed):
    """
    per_cat_groups: æ¥è‡ª discover_groups_by_category çš„ per_cat_groups[K][cat] -> [group]
    per_cat_N: æ¯ä¸ªç±»åˆ«çš„ç›®æ ‡æ¡æ•°ï¼ˆå·²æ˜¯ N/24 å‡åˆ†ï¼‰
    è¿”å›ï¼šselected_groups æ±‡æ€»ä¸º list[tuple(sorted_ids)]ï¼Œä»¥åŠæŒ‰ç±»/æŒ‰Kç»Ÿè®¡
    """
    rng = random.Random(seed)
    used_groups = set()  # å»é‡ï¼šä¸€ä¸ªç»„åªèƒ½è¢«ä¸€ä¸ªç±»åˆ«æ‹¿èµ°
    selected = defaultdict(lambda: defaultdict(list))  # selected[cat][K] = [group,...]

    for cat in BALANCE_CATEGORIES:
        Nc = per_cat_N.get(cat, 0)
        if Nc <= 0:
            continue
        targets_K = compute_targets_per_cat(Nc, K_DIST)

        for K in K_LIST:
            need = targets_K.get(K, 0)
            if need <= 0:
                continue
            cand = per_cat_groups.get(K, {}).get(cat, [])
            if not cand:
                continue
            # å»æ‰å·²ç”¨ç»„
            cand = [g for g in cand if g not in used_groups]
            if not cand:
                continue
            if len(cand) <= need:
                pick = cand
            else:
                pick = rng.sample(cand, need)
            for g in pick:
                used_groups.add(g)
            selected[cat][K].extend(pick)

    # å±•å¼€
    all_groups = []
    for cat in BALANCE_CATEGORIES:
        for K in K_LIST:
            all_groups.extend(selected[cat][K])

    # ç»Ÿè®¡
    stat_cat = {cat: sum(len(selected[cat][K]) for K in K_LIST) for cat in BALANCE_CATEGORIES}
    stat_K = Counter({K: 0 for K in K_LIST})
    for cat in BALANCE_CATEGORIES:
        for K in K_LIST:
            stat_K[K] += len(selected[cat][K])

    return all_groups, selected, stat_cat, dict(stat_K)

# ---------------- Assemble ----------------
def assemble_records(groups, by_image):
    final = []
    for ids_sorted in groups:
        ids = list(ids_sorted)
        m0 = by_image[ids[0]]
        rec = {
            "image_file_name": [],
            "image_panel_type": [],
            "image_panel_subtype": [],
            "image_primary_label": [],
            "image_secondary_label": [],
            "image_size": [],
            "caption": [],
            "context": [],
            "image_id": [],
            "image_wds_tar": [],
            "image_wds_member": [],
            "image_wds_path": [],
            "article_accession_id": m0.get("article_accession_id"),
            "article_title": m0.get("article_title"),
        }
        cap0 = by_image[ids[0]].get("caption", "")
        for iid in ids:
            m = by_image[iid]
            rec["image_id"].append(iid)
            rec["image_file_name"].append(m.get("image_file_name"))
            rec["image_panel_type"].append(m.get("image_panel_type"))
            rec["image_panel_subtype"].append(m.get("image_panel_subtype"))
            rec["image_primary_label"].append(m.get("image_primary_label") or [])
            rec["image_secondary_label"].append(m.get("image_secondary_label") or [])
            rec["image_size"].append(m.get("image_size") or [None, None])
            rec["caption"].append(cap0)
            rec["context"].append(m.get("context") or [])
            rec["image_wds_tar"].append(m.get("image_wds_tar"))
            rec["image_wds_member"].append(m.get("image_wds_member"))
            rec["image_wds_path"].append(m.get("image_wds_path"))
        final.append(rec)
    return final

# ---------------- CLI ----------------
def main():
    ap = argparse.ArgumentParser(description="Full-dataset parallel sampler with per-category balance & K-distribution.")
    ap.add_argument("--base", required=True, help="WebDataset æ ¹ç›®å½•ï¼ˆå« commercial/noncommercial/otherï¼‰")
    ap.add_argument("--out", required=True, help="è¾“å‡º JSON æ–‡ä»¶è·¯å¾„")
    ap.add_argument("--total", type=int, default=50, help="ç›®æ ‡æ ·æœ¬æ€»æ•° Nï¼ˆæŒ‰ 24 ä¸ªäºŒçº§ç±»å‡åˆ†ï¼‰")
    ap.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    ap.add_argument("--workers", type=int, default=os.cpu_count(), help="å¹¶è¡Œè¿›ç¨‹æ•°")
    args = ap.parse_args()

    # 1) å¹¶è¡Œç´¢å¼•
    print("--- Phase 1: Building mini index in parallel ---")
    by_image, by_article = build_mini_index_parallel(args.base, args.workers)
    print(f"  images indexed: {len(by_image)}  |  articles: {len(by_article)}")

    # 2) ç»„å‘ç°ï¼ˆæ–‡ç« å†…ã€caption å®Œå…¨ç›¸åŒã€full-useã€ä¸æˆªæ–­ï¼‰ï¼Œå¹¶æŒ‰ 24 ç±»æŒ‚æ¥å€™é€‰
    print("\n--- Phase 2: Discovering full-use groups per category ---")
    per_cat_groups, available = discover_groups_by_category(by_article, by_image, K_max=6)
    print("  Available groups per K (per-category counts shown as total sums):")
    for K in K_LIST:
        totalK = sum(available.get(K, {}).values())
        print(f"    K={K}: total groups={totalK}")

    # 3) 24 ç±»å‡åˆ† N
    print("\n--- Phase 3: Targets ---")
    per_cat_N = split_evenly_total(args.total, BALANCE_CATEGORIES)
    print(f"  Per-category N (sum={sum(per_cat_N.values())}):")
    # åªæ‰“å°å‰å‡ é¡¹é¿å…åˆ·å±
    preview = list(per_cat_N.items())[:8]
    for k,v in preview:
        print(f"    {k}: {v}")
    if len(per_cat_N) > 8:
        print("    ...")

    # 4) é‡‡æ ·ï¼ˆåŒä¸€ç»„ä¸å¯é‡å¤åˆ†é…ï¼›æŸç±»æŸKä¸è¶³ => æ‹¿åˆ°å¤šå°‘ç®—å¤šå°‘ï¼‰
    print("\n--- Phase 4: Sampling by category & K ---")
    groups, selected, stat_cat, stat_K = sample_by_category(per_cat_groups, per_cat_N, seed=args.seed)
    print(f"  Selected groups total: {len(groups)}")
    print("  Selected per K:", stat_K)
    print("  Selected per category (top few):")
    for c, n in list(stat_cat.items())[:8]:
        print(f"    {c}: {n}")
    if len(stat_cat) > 8:
        print("    ...")

    # 5) ç»„è£…å¹¶ä¿å­˜
    print("\n--- Phase 5: Assembling final JSON records ---")
    final = assemble_records(groups, by_image)
    os.makedirs(os.path.dirname(args.out), exist_ok=True)
    with open(args.out, "w", encoding="utf-8") as f:
        json.dump(final, f, ensure_ascii=False, indent=2)

    print("\n======================================================")
    print("ğŸ‰ Done")
    print(f"- Saved to: {os.path.abspath(args.out)}")
    print(f"- Records:  {len(final)}   (target N={args.total}, æŸäº›ç±»/K ä¸è¶³åˆ™ä¼šå°‘)")
    print("======================================================")

if __name__ == "__main__":
    main()
